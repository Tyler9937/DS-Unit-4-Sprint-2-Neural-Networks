{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_431_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyler9937/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/Copy_of_LS_DS_431_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### **Input Layer:** Where the data that is being trained is entered. There can be as manny of these input nodes as needed\n",
        "### **Hidden Layer:** A layer of at least\n",
        "### **Output Layer:** Where Our results go, the predictions of the model.\n",
        "### **Neuron: Basically** a function where all the inputs are passed through multiplied by their weights, added to by a bias and then passed through a activation function such as the sigmoid function\n",
        "### **Weight:** A wheight is a adjustment that is modified through each epoch to achevie a accurate model. Each weight is multiplied by an input. the weights represent the value or importance of a given input in order to achive a pre defined result.\n",
        "### **Activation Function:** A function that normalizes the data into probabilites. Is the aspect of a neral network that is most similar to biolagy \n",
        "### **Node Map:** Is a visual diagram that maps out the architecture of a neral network. It consist of a variety of nodes such as input, hidden, output nodes.\n",
        "### **Perceptron:** Is the simplest of neral network models and consits of an input layer and an output layer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### Your Answer Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH0V1zoZKpg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'x3': [1,1,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAaCJyVieG-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  sx = sigmoid(x)\n",
        "  return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vL9tu0Rn2LR",
        "colab_type": "code",
        "outputId": "c03f1e77-2768-4a98-be64-23e09846f806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [1, 0, 1],\n",
              "       [0, 1, 1],\n",
              "       [1, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "outputId": "e3f58211-ba7c-409f-d6c5-7a13be3ab67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "inputs = df.iloc[0:4,0:3]\n",
        "inputs = np.array(inputs)\n",
        "#correct_outputs = np.array(df['y'])\n",
        "weights = 2 * np.random.random((3,1)) - 1\n",
        "\n",
        "correct_outputs = [[1], [1], [1], [0]]\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "  weighted_sum = np.dot(inputs, weights)\n",
        "\n",
        "  activated_output = sigmoid(weighted_sum)\n",
        "\n",
        "  error = correct_outputs - activated_output\n",
        "\n",
        "  adjustments = error * sigmoid_derivative(activated_output)\n",
        "\n",
        "  weights += np.dot(inputs.T, adjustments)\n",
        "\n",
        "print('weights after training \\n', weights)\n",
        "print('outputs after training \\n', activated_output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights after training \n",
            " [[-7.20510141]\n",
            " [-7.20510119]\n",
            " [10.86342607]]\n",
            "outputs after training \n",
            " [[0.9999808 ]\n",
            " [0.97484764]\n",
            " [0.97484765]\n",
            " [0.02803773]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dSuRYA7p7am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b8aI65a4qjOX"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joiwOWAOKphD",
        "colab_type": "code",
        "outputId": "d00f3074-53db-414d-a966-02f4f459836c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI5lEhFeKphH",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOwyGMtQIO-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "\n",
        "  def __init__(self, learning_rate=.05, n_iters=100):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "    self.activation_func = self._unit_step_func\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Init weights\n",
        "    self.weights = np.zeros(n_features)\n",
        "    self.bias = 0\n",
        "\n",
        "    y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        "\n",
        "    for _ in range(self.n_iters):\n",
        "      for idx, x_i in enumerate(X):\n",
        "        linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "\n",
        "        update = self.lr * (y_[idx] - y_predicted)\n",
        "        self.weights += update * x_i\n",
        "        self.bias += update\n",
        "\n",
        "  def predict(self, X):\n",
        "    linear_output = np.dot(X, self.weights) + self.bias\n",
        "    y_predicted = self.activation_func(linear_output)\n",
        "    return y_predicted\n",
        "\n",
        "  def _unit_step_func(self, x):\n",
        "    return np.where(x >= 0, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY63WwXcKuGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPDtXqQNKtjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "feats = list(diabetes)[:-1]\n",
        "outcome = list(diabetes)[8]\n",
        "\n",
        "X = diabetes[feats]\n",
        "y = diabetes[outcome]\n",
        "\n",
        "transformer = Normalizer().fit(X)\n",
        "X = transformer.transform(X)\n",
        "y = np.array(y)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng1p6EwNKufr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g-iAKipKMsP",
        "colab_type": "code",
        "outputId": "0758992c-3a23-40f0-bc0e-ff7aea1b3d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "  return accuracy\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "p = Perceptron(learning_rate=0.01, n_iters=100)\n",
        "p.fit(X_train, y_train)\n",
        "predictions = p.predict(X_test)\n",
        "\n",
        "print(\"Perceptron classification accuracy\", accuracy(y_test, predictions))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "plt.scatter(X_train[:,0], X_train[:,1], marker='o', c=y_train)\n",
        "\n",
        "x0_1 = np.amin(X_train[:,0])\n",
        "x0_2 = np.amax(X_train[:,0])\n",
        "\n",
        "x1_1 = (-p.weights[0] * x0_1 - p.bias) / p.weights[1]\n",
        "x1_2 = (-p.weights[0] * x0_2 - p.bias) / p.weights[1]\n",
        "\n",
        "ax.plot([x0_1, x0_2], [x1_1, x1_2], 'k')\n",
        "\n",
        "ymin = np.amin(X_train[:,1])\n",
        "ymax = np.amax(X_train[:,1])\n",
        "ax.set_ylim([ymin-3, ymax+3])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perceptron classification accuracy 0.7662337662337663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRIyTIBdCiBgnQS6EEDFOglwIIWLc/wNVk3d4qwaPDAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3h2iF8FM19e",
        "colab_type": "code",
        "outputId": "59bec22a-69e2-44c5-96d3-7bc4c26a871d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "p = Perceptron(n_iters=10000)\n",
        "p.fit(X, y)\n",
        "p.predict(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khiu7rhCOBZG",
        "colab_type": "code",
        "outputId": "ccf20055-fb97-4e8b-d58b-62fc79744b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   ,  98.   ,  58.   , ...,  34.   ,   0.43 ,  43.   ],\n",
              "       [  2.   , 112.   ,  75.   , ...,  35.7  ,   0.148,  21.   ],\n",
              "       [  2.   , 108.   ,  64.   , ...,  30.8  ,   0.158,  21.   ],\n",
              "       ...,\n",
              "       [  8.   ,  95.   ,  72.   , ...,  36.8  ,   0.485,  57.   ],\n",
              "       [  2.   , 146.   ,  70.   , ...,  28.   ,   0.337,  29.   ],\n",
              "       [  8.   ,  74.   ,  70.   , ...,  35.3  ,   0.705,  39.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}